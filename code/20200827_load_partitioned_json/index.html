
  
<!doctype html>
<html class="no-js" lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="siteBaseUrl" content="https://www.datarchy.tech/">
    <meta name="author" content="Wissem Belguidoum">
    <meta name="description" content="Wissem Belguidoum Data Engineer Datarchy">
    <meta name="keywords" content="blog, apache spark, dataframe, delta architecture, data lake, machine learning, data pipline, stream processing, apache flink, apache hadoop, data engineering, data engineer">
    <meta name="generator" content="Hugo 0.69.0" />
    <title>
        
           
               How to optimise loading partitioned JSON data in Spark ? &vert; Data Programmers
           
        
    </title>
    <meta name="description" content="How to optimise loading partitioned JSON data in Spark ? - Wissem Belguidoum Data Engineer Datarchy">
    <meta itemprop="name" content="How to optimise loading partitioned JSON data in Spark ?">
    <meta itemprop="description" content="How to optimise loading partitioned JSON data in Spark ? - Wissem Belguidoum Data Engineer Datarchy">
    <meta property="og:title" content="How to optimise loading partitioned JSON data in Spark ?">
    <meta property="og:description" content="How to optimise loading partitioned JSON data in Spark ? - Wissem Belguidoum Data Engineer Datarchy">
    <meta property="og:image" content="https://www.datarchy.tech/spark_with_json.png">
    <meta property="og:url" content="https://www.datarchy.tech/code/20200827_load_partitioned_json/">
    <meta property="og:site_name" content="Data Programmers">
    <meta property="og:type" content="article">

    
	<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	<link rel="manifest" href="/site.webmanifest">
	<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
	<meta name="msapplication-TileColor" content="#da532c">
	<meta name="theme-color" content="#ffffff"> 

    <script src="/modernizr-simple.js"></script>

    
    <link href="/code/20200827_load_partitioned_json/" rel="alternate" type="application/rss+xml" title="Data Programmers" />
    <link href="/code/20200827_load_partitioned_json/" rel="feed" type="application/rss+xml" title="Data Programmers" />
    

    

    <link rel="stylesheet" href="https://www.datarchy.tech/theme.css">

    

    
        
            <link rel="stylesheet" href="https://www.datarchy.tech/datarchy.css">
        
    
</head>

<body class="bilberry-hugo-theme">

    
    <nav>

    <div class="container">
        <ul class="topnav">
            
                
                    <li><a href="https://www.datarchy.tech/page/about/">About</a></li>
                
            
                
                    <li><a href="https://www.linkedin.com/company/datarchy" target="_blank">LinkedIn</a></li>
                
            
        </ul>

        
    </div>
</nav>


    
    <header>

        <div class="container">
            <div class="logo">
                <a href="/" class="logo">
                    
                        <img src="/chrome-192x192.png" alt="">
                    

                    <span class="overlay"><i class="fa fa-home"></i></span>
                </a>
            </div>
            <div class="titles">
                <h3 class="title">
                    <a href="/">
                        Data Programmers
                    </a>
                </h3>

                
                    <span class="subtitle">Let&#39;s learn data engineering together!</span>
                
            </div>

            

            
                <div class="toggler">
            
                    <i class="fa fa-bars" aria-hidden="true"></i>
                </div>
            </div>
    </header>


    <div class="main container">
        
    <div class="article-wrapper u-cf single">
        
            <a class="bubble" href="https://www.datarchy.tech/code/20200827_load_partitioned_json/">
    <i class="fas fa-fw fa-code"></i>
</a>

<article class="default article">
    
    <div class="featured-image">
        <a href="https://www.datarchy.tech/code/20200827_load_partitioned_json/">
            <img src="/spark_with_json.png" alt="">
        </a>
    </div>


    <div class="content">
    <h1 class="article-title">
        <a href="https://www.datarchy.tech/code/20200827_load_partitioned_json/">
            How to optimise loading partitioned JSON data in Spark ?
        </a>
    </h1>

    <div class="meta">
        
            
                <span class="date moment">2020-08-27</span>
            
        

        
            
                <span class="readingTime">6 min read</span>
            
        

        
            <span class="categories">
                
                    
                    
                        <a href="https://www.datarchy.tech/categories/apache-spark/">Apache Spark</a>
                    
                
                    
                    
                        <a href="https://www.datarchy.tech/categories/tutorial/">Tutorial</a>
                    
                
            </span>
        

        
            <span class="author">
                
                
                    <a href="https://www.datarchy.tech/author/wissem-belguidoum/">Wissem Belguidoum</a>
                
            </span>
        
    </div>

    
        <p>In this tutorial we will explore ways to optimise loading partitioned JSON data in Spark.</p>
<p>I have used the SF Bay Area Bike Share dataset, you can find it <a href="https://www.kaggle.com/benhamner/sf-bay-area-bike-share/data#"><strong>here</strong></a>. The original data (<em>status.csv</em>) have gone through few transformations. The result looks like:</p>
<p><img src="tree.png" alt="Partitioned JSON data"></p>
<h2 id="loading-from-partitioned-json-files">Loading from partitioned JSON files</h2>
<hr>
<p>We will load the data filtered by station and month :</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#66d9ef">val</span> df1 <span style="color:#66d9ef">=</span> spark<span style="color:#f92672">.</span>read
	<span style="color:#f92672">.</span>json<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;file:///data/bike-data-big/partitioned_status.json&#34;</span><span style="color:#f92672">)</span>
	<span style="color:#f92672">.</span>filter<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;station_id = 10 and (month in (&#39;2013-08&#39;, &#39;2013-09&#39;))&#34;</span><span style="color:#f92672">)</span>
</code></pre></div><p>Despite the fact that the code above does not contain any action yet, Spark starts three jobs that took few minutes to complete (on a local setting, with 8 cores and 32 Gigs or RAM):
<img src="slow_json_loading.png" alt="Slow JSON Loading"></p>
<ul>
<li>Job 0 and Job 1 : Spark (and more specifically the Data Source API) is listing the content of the root folder and its subfolders, in order to discover the partitioning columns and map each column value to a file path. The result of this job is an <code>InMemoryFileIndex</code> object that will be used later to access the data.</li>
<li>To do partition discovery, Spark does not systematically trigger jobs; this depends on a threshold that is defined in configuration, namely <code>spark.sql.sources.parallelPartitionDiscovery.threshold</code> (default value 32). If the number of paths that constitue the data is below this threshold, Spark will achieve partition discovery directly on the driver, otherwise, Spark will launch parallel jobs, as we have seen in our case. You can take a look at the implementation of this logic <a href="https://github.com/apache/spark/blob/v3.0.0/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/InMemoryFileIndex.scala#L186"><strong>here</strong></a>.</li>
<li>Job 2 : Spark is infering schema by scanning the entire dataset.</li>
</ul>
<p>Let’s explore a little bit further, by taking a look at the physical plan generated by Spark for this dataframe :</p>
<pre><code class="language-fulltext" data-lang="fulltext">== Physical Plan ==
FileScan json [bikes_available#7L,docks_available#8L,time#9,station_id#10,month#11], Batched: false, DataFilters: [], Format: JSON, Location: InMemoryFileIndex[file:/data/bike-data-big/partitioned_status.json], PartitionFilters: [isnotnull(station_id#10), (station_id#10 = 10), month#11 IN (2013-08,2013-09)], PushedFilters: [], ReadSchema: struct&lt;bikes_available:bigint,docks_available:bigint,time:string&gt;
</code></pre><ul>
<li>You can see that the physical plan makes use of both the <code>InMemoryFileIndex</code> and the <code>ReadSchema</code> that have been built by the Data Source API in the preceding steps.</li>
<li>Also, you can see that the <code>InMemoryFileIndex</code> is built on top of the root folder (<em>file:/data/bike-data-big/partitioned_status.json</em>). Despite the fact that we have provided a filter, Spark (version 3.0) did not push the filter down to be used in the <code>FileScan</code> operator to do partition pruning.</li>
</ul>
<p>So far, we have identified three different issues related to loading partitioned JSON data in Spark :</p>
<ul>
<li><strong>Issue 1</strong> : Spark will run partition discovery jobs each time we load the data (depends on the number of folders).</li>
<li><strong>Issue 2</strong> : Also, Spark will launch a job that will scan the whole dataset in order to infer the schema.</li>
<li><strong>Issue 3</strong> : Predicate pushdown is disabled, although Spark has collected all the meta-data needed.</li>
</ul>
<p>In the next section, we&rsquo;ll try to cover some solutions to these issues.</p>
<h2 id="solution-1--using-basepath">Solution 1 : Using <code>basePath</code></h2>
<hr>
<p>The first approach is to reduce the scope of the data by explicitly specifying the folders of interest:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#66d9ef">val</span> df2 <span style="color:#66d9ef">=</span> spark<span style="color:#f92672">.</span>read
<span style="color:#f92672">.</span>option<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;basePath&#34;</span><span style="color:#f92672">,</span> <span style="color:#e6db74">&#34;file:///data/bike-data-big/partitioned_status.json&#34;</span><span style="color:#f92672">)</span>
<span style="color:#f92672">.</span>json<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;file:///data/bike-data-big/partitioned_status.json/station_id=10&#34;</span><span style="color:#f92672">)</span>
<span style="color:#f92672">.</span>filter<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;station_id = 10 and (month in (&#39;2013-08&#39;, &#39;2013-09&#39;))&#34;</span><span style="color:#f92672">)</span>
</code></pre></div><ul>
<li>Since we are only interested in data from station n°10, we pass the sub-folder that contains the data of this station to the JSON reader.</li>
<li><code>basePath</code> : this option will override the path used by Spark in partition discovery. If we do not provide <code>basePath</code> option, the default base path will be the path passed to the JSON reader (<em>&hellip;/partitioned_status.json/station_id=10</em>), which will result in the <code>station_id</code> column not being added to the schema.</li>
</ul>
<p>By applying this method, loading the data becomes significantly faster:
<img src="basePath.png" alt="Using basePath option"></p>
<p>Even with this method, predicate pushdown is still disabled. But since we pre-filtered the data by specifying a sub-folder, the <code>InMemoryFileIndex</code> is built on top of that folder :</p>
<pre><code class="language-fulltext" data-lang="fulltext">== Physical Plan ==
FileScan json [bikes_available#184L,docks_available#185L,time#186,station_id#187,month#188] Batched: false, DataFilters: [], Format: JSON, Location: InMemoryFileIndex[file:/data/bike-data-big/partitioned_status.json/station_id=10], PartitionFilters: [isnotnull(station_id#187), (station_id#187 = 10), month#188 IN (2013-08,2013-09)], PushedFilters: [], ReadSchema: struct&lt;bikes_available:bigint,docks_available:bigint,time:string&gt;
</code></pre><h3 id="solution-2--specifying-a-sampling-ratio">Solution 2 : Specifying a sampling ratio</h3>
<hr>
<p>By default JSON data source will try to infer schema by scanning the entire data set. There is an option called <code>samplingRatio</code> that we can tweak in order to make Spark scan a part of the data.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#66d9ef">val</span> df3 <span style="color:#66d9ef">=</span> spark<span style="color:#f92672">.</span>read
<span style="color:#f92672">.</span>option<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;samplingRatio&#34;</span><span style="color:#f92672">,</span> <span style="color:#ae81ff">0.001</span><span style="color:#f92672">)</span>
<span style="color:#f92672">.</span>json<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;file:///data/bike-data-big/partitioned_status.json&#34;</span><span style="color:#f92672">)</span>
<span style="color:#f92672">.</span>filter<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;station_id = 10 and (month in (&#39;2013-08&#39;, &#39;2013-09&#39;))&#34;</span><span style="color:#f92672">)</span>
</code></pre></div><p><img src="samplingRatio.png" alt="Sampling Ratio"></p>
<ul>
<li>Partition discovery jobs are still there, but the schema inference job is significantly faster, because we are scanning only 0.1% of the total data set instead of 100% by default.</li>
</ul>
<h3 id="solution-3--accessing-via-unmanaged-table">Solution 3 : Accessing via unmanaged table</h3>
<hr>
<p>Both solutions presented so far reduced the time of schema inference, but did not provide a solution to enable predicate pushdown. This section will give a solution that will resolve the three issues altogether.</p>
<p>We will create an unmanaged table on top of the JSON data, and will load and query the data from that table :</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala">spark<span style="color:#f92672">.</span>sql<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;CREATE TABLE IF NOT EXISTS sf_bike_status USING JSON OPTIONS (path &#39;file:///data/bike-data-big/partitioned_status.json&#39;)&#34;</span><span style="color:#f92672">)</span>
</code></pre></div><ul>
<li><code>CREATE TABLE</code> command will launch partition discovery and schema inference in the same way as we have seen before.</li>
<li>The metadata collected will be stored in the Spark catalog, and reused whenever the data is accessed.</li>
</ul>
<p>One last step, before we can query the data, we need to call <code>MSCK REPAIR TABLE</code> in order  to register the existing partitions in the catalog:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala">spark<span style="color:#f92672">.</span>sql<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;MSCK REPAIR TABLE sf_bike_status&#34;</span><span style="color:#f92672">)</span>
</code></pre></div><ul>
<li>This command is described in more detail <a href="https://spark.apache.org/docs/3.0.0-preview/sql-ref-syntax-ddl-repair-table.html"><strong>here</strong></a>.</li>
</ul>
<p>From now on, we can query the data using the unmanaged table:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#66d9ef">val</span> df4 <span style="color:#66d9ef">=</span> spark<span style="color:#f92672">.</span>read
<span style="color:#f92672">.</span>table<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;sf_bike_status&#34;</span><span style="color:#f92672">)</span>
<span style="color:#f92672">.</span>filter<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;station_id = 10 and (month in (&#39;2013-08&#39;, &#39;2013-09&#39;))&#34;</span><span style="color:#f92672">)</span>
</code></pre></div><ul>
<li>There was no need to infer the schema, because it has been loaded from the catalog.</li>
<li>Compared to reading directly from JSON file, the loading time is reduced from a few minutes to sub-second.</li>
</ul>
<p>What about predicate pushdown ?</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala">df4<span style="color:#f92672">.</span>expalin<span style="color:#f92672">()</span>
</code></pre></div><pre><code class="language-fulltext" data-lang="fulltext">== Physical Plan ==
FileScan json default.sf_bike_status[bikes_available#0L,docks_available#1L,time#2,station_id#3,month#4] Batched: false, DataFilters: [], Format: JSON, Location: InMemoryFileIndex[file:/data/bike-data-big/partitioned_status.json/station_id=10/month=2013-08, f..., PartitionFilters: [isnotnull(station_id#3), (station_id#3 = 10), month#4 IN (2013-08,2013-09)], PushedFilters: [], ReadSchema: struct&lt;bikes_available:bigint,docks_available:bigint,time:string&gt;
</code></pre><ul>
<li>As you can see in the <code>InMemoryFileIndex</code>, reading the data via a table has enabled predicate pushdown. This leads to improvement in read performance.</li>
</ul>
<p>It is worth saying that even when reading from a table, partition discovery is still there. But, since we have predicate pushdown enabled, the partition discovery is limited to the scope of the paths covered by the filter. In our case, the partition discovery did not trigger Spark jobs, because the number of paths (2 paths after predicate pushdown) is below the parallel discovery threshold (default value is 32), as discussed in the first section.</p>
<h3 id="conclusion">Conclusion</h3>
<hr>
<p>Reading partitioned JSON files (or even partitioned CSV files with <code>inferSchema=true</code>) can take a significant amount of time, during which Spark does two things: partition discovery and schema inference.</p>
<p>The other important issue we have identified is that Spark does not apply predicate pushdown optimisation when reading from JSON partitioned data (as far as version 3.0.0).</p>
<p>We have explored a few ways to handle these issues, and the most effective solution was to create an unmanaged table on top of the JSON files. However, there is one problem with this solution: we need to call <code>MSCK REPAIR TABLE</code> in order to update the catalog, whenever the data is updated.</p>
<p>Thank you for reading this,</p>
<p>You can find the code in the following Gist :
<script type="application/javascript" src="https://gist.github.com/elbombardi/9dcf09c9e649288a37399a12dfd84cdd.js"></script>
</p>

    
</div>

    
<div class="footer">


    
        <div class="tags">
            <i class="fa fa-tags"></i>
            <div class="links">
                
                    
                    
                    <a href="https://www.datarchy.tech/tags/spark/">Spark</a>
                    
                
                    
                    
                    <a href="https://www.datarchy.tech/tags/spark-dataframe/">Spark DataFrame</a>
                    
                
                    
                    
                    <a href="https://www.datarchy.tech/tags/json/">Json</a>
                    
                
            </div>
        </div>
    

    
</div>

</article>

        
    </div>

    
        <div id="comments-container">
            <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "https-www-datarchy-tech" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
            

        </div>
    

    </div>

    
<footer>
    <div class="container">

        
        <div class="recent-posts">
            <strong>Latest posts</strong>
            <ul>
                
                
                    <li>
                        <a href="https://www.datarchy.tech/code/20200827_load_partitioned_json/">How to optimise loading partitioned JSON data in Spark ?</a>
                    </li>
                
                    <li>
                        <a href="https://www.datarchy.tech/code/20200820_spark_rows_number/">How to add row numbers to a Spark DataFrame?</a>
                    </li>
                
                    <li>
                        <a href="https://www.datarchy.tech/code/20200814_spark_count_per_partition/">Spark DataFrame - two ways to count the number of rows per partition</a>
                    </li>
                
            </ul>
        </div>
        

        
        <div class="categories">
            <a href="/categories/"><strong>Categories</strong></a>
            <ul>
                
                <li>
                    <a href="/categories/apache-spark">Apache spark
                        (3)</a>
                </li>
                
                <li>
                    <a href="/categories/tutorial">Tutorial
                        (3)</a>
                </li>
                
                <li>
                    <a href="/categories/motivation">Motivation
                        (1)</a>
                </li>
                
            </ul>
        </div>
        

        <div class="right">
            
            <div class="external-profiles">
                <strong>Social media</strong>

                
                <a href="https://www.linkedin.com/company/datarchy" target="_blank"><i class="fab fa-linkedin"></i></a>
                
                <a href="https://github.com/datarchy" target="_blank"><i class="fab fa-github"></i></a>
                
            </div>
            

            
        </div>
    </div>
</footer>


<div class="credits">
    <div class="container">
        <div class="copyright">
            <a href="https://github.com/datarchy" target="_blank">
                &copy;
                
                2020
                
                by Datarchy
            </a>
            
        </div>
        <div class="author">
            <a href="https://github.com/Lednerb/bilberry-hugo-theme"
                target="_blank"> </a>
        </div>
    </div>
</div>


    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-175071430-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


    


    <script type="text/javascript" src="https://www.datarchy.tech/theme.js"></script>

    
    
    

    
</body>

</html>
